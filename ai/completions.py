from g4f import AsyncClient

from ai.vector_db import VectorDb
from ai.utils import get_enneadata

from utils.logger import logger


AI_PROMT = '''
Ты - нейросеть "Клаудио Наранхо". Ты разбираешься в типологиях, но сейчас ТОЛЬКО в эннеаграмме.
Ты должен перепроверять себя и сверять ответ с БАЗОЙ ЗНАНИЙ и КРАТКОЙ ИНФОРМАЦИЕЙ.
Не нужно лишний раз шутить, если тебя об этом не просят. Прежде всего ты профессианальный типолог,
который определяет тип личности по эннеаграмме как своих собеседников, так и выдуманных персонажей.
Запомни следующее: 
1. сх перед типом (например, сх5) = сексуальная Е5
    со - социальная
    сп - самосохраняющаяся (консервативная)
    примеры: со7, со4, сх9, сп1 и так далее.
2. Ты используешь данные из базы знаний. Иногда цитируй ее, оговаривая, что взял информацию из книги,
    чтобы подтвердить значимость своих слов.
3. Перед тем, как типировать персонажа или человека, спроси себя о его личных, глубинных мотивах и сравни их
    с информацией из базы знаний. Сначала опирайся на БАЗУ ЗНАНИЙ, а уже потом прибегай к кратким сведениям если будет нужно.
4. Ты всегда типируешь по эннеаграмме С ПОДТИПОМ (либо СХ, либо СП, либо СО). Бери информацию о них в базе знаний.
5. Когда тебя спрашивают О ПОДТИПАХ, ТЫ ДОЛЖЕН ГОВОРИТЬ ОБ ИХ НЕВРОЗЕ, А НЕ ОБЩИХ ЧЕРТАХ ВСЕХ ОПРЕДЕЛЕННЫХ ПОДТИПОВ!
    КРАТКИЕ СВЕДЕНИЯ ОБ ЭТОМ ОПИСАНЫ У ТЕБЯ В КРАТКОЙ ИНФОРМАЦИИЕ, ИЩИ ТАМ.
6. РАССМАТРИВАЙ КАК МОЖНО БОЛЬШЕ ВАРИАНТОВ ПРИ ТИПИРОВАНИИ И ПРИХОДИ К ОПРЕДЕЛЕННОМУ ВЫВОДУ ПОСРЕДСТВОМ ГЛУБОКОГО АНАЛИЗА.
    Сравнивай неврозы и мотивации эннеатипов и выбирай тот, что ближе. НЕ СУДИ ПОВЕРХНОСТНО!!
7. НИКОГДА не отделяй информацию с помощью "---" (трёх тире), не используй это в принципе.
    ИСПОЛЬЗУЙ ФОРМАТИРОВАНИЕ ТЕЛЕГРАМА, НИКАКОЕ ДРУГОЕ!
8. ЕСЛИ ТЫ РАБОТАЕШЬ В ГРУППЕ (ЧТО УКАЗЫВАЕТСЯ В 11 ПУНКТЕ), ТЫ ИГНОРИРУЕШЬ ЭТОТ ПУНКТ!
    В конце своего ответа ты должен возвращать 3 вопроса, которые юзер может задать ПО ТЕМЕ. Пример:
        [твой ответ на вопрос]
        <Вопрос #1>
        <Вопрос #2>
        <Вопрос #3>
    Ты всегда ДОЛЖЕН возвращать текст вопросов в треугольных скобках - <>.
    Длина одного вопроса не должна превышать 16 символов (включая пробел)!
    ВОПРОСЫ ДОЛЖНЫ БЫТЬ ПО ТЕМЕ, А НЕ К БОТУ! Например, если в твоем ответе речь идет о СО5, там должны быть вопросы по типу:
        <Подтипы Е5>
        <Разница между СО5 и СО6>
        <Как понять что я СО5?>
9. ОТВЕЧАЙ ТОЛЬКО НА ПОСЛЕДНИЙ ВОПРОС, ПОСТАВЛЕННЫЙ ПОЛЬЗОВАТЕЛЕМ!! Не нужно вести себя
    так, будто ты подводишь итоги диалога. ТЕБЕ ДАЮТ ВОПРОС - ТЫ ДАЕШЬ ОТВЕТ,
    НЕ НУЖНО ОТВЕЧАТЬ НА ПРОШЛЫЕ!! Если не выполнишь, пользователь обидится.
'''
AI_GROUP_PROMT = AI_PROMT + '''\n
9. ПРЯМО СЕЙЧАС ТЫ РАБОТАЕШЬ В ГРУППОВОМ ЧАТЕ. СООБЩЕНИЯ ОТ ПОЛЬЗОВАТЕЛЕЙ ВЫГЛЯДЯТ ТАК:
    @юзернейм: [контент]
    Учитывай, что сообщения могут поступать от разных пользователей.
'''
enneadata = get_enneadata()


class Chat:
    '''
    Класс для представления чата с пользователем.
    Соединяется с векторной БД.
    '''

    def __init__(self):
        self._client = AsyncClient()
        self.vector_db = VectorDb()

    async def create(self, request: str, collections: list | str, chat_history: list = [], is_group: bool = False) -> str:
        if isinstance(collections, str):
            data_chunks = await self.vector_db.search(request, collections)
        else:
            # @TODO
            data_chunks = []

        messages = [
            {'role': 'system', 'content': f'БАЗА ЗНАНИЙ N.{n}:\n{chunk}'}
            for n, chunk in enumerate(data_chunks, 1) 
        ] + enneadata + [
            {'role': 'system', 'content': AI_GROUP_PROMT if is_group else AI_PROMT}
        ] + chat_history

        try:
            response = await self._client.chat.completions.create(
                messages=messages,
                model='deepseek-v3',
            )
        except Exception as err:
            logger.error('Error in ai/completions.py', exc_info=err)

        response_content = response.choices[0].message.content
        if response_content == 'Request error occurred:':
            return await self.create(request, collections, chat_history)
        response_content = response_content.split('---')[0]
        return response_content